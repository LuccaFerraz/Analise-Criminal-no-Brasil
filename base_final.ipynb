{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import unidecode\n",
    "import os\n",
    "\n",
    "path_regioes = \"divisoes_regionais.csv\" \n",
    "path_limites_mun = \"Shapefiles_auxiliares\\limite_municipal\\LimiteMunicipal.shp\"\n",
    "path_PIB = \"Processamento_base_PIB_MUN\\PIB_processado.csv\"\n",
    "path_ipdm = \"Processamento_base_IPDM\\ipdm_processada.csv\"\n",
    "path_est_pop = \"Processamento_base_EST_POP\\EST_POP_processada.csv\"\n",
    "path_regiao_imediata = \"Shapefiles_auxiliares\\regiao_geografica_imediata\\Regiao Geografica Imediata.shp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processamento Individual de cada Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "divisao_regional = pd.read_csv(path_regioes)\n",
    "divisao_regional = divisao_regional[divisao_regional['Nome_UF'] == 'São Paulo']\n",
    "\n",
    "divisao_regional.drop(columns=['UF', 'Nome_UF', 'Mesorregião Geográfica',\n",
    "                      'Nome_Mesorregião', 'Microrregião Geográfica',\n",
    "                      \"Nome_Microrregião\", \"Município\"], inplace=True)\n",
    "\n",
    "divisao_regional.rename(columns={'Código Município Completo': 'cod_ibge',\n",
    "                        'Nome_Município': 'Municipio'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "limites_regionais = gpd.read_file(path_limites_mun)\n",
    "limites_regionais.drop(columns=['GID_RA','GID_RG','GID_RM', 'GID_RM', 'RM', 'AU', 'GID_AU', 'RA', 'RG'], inplace=True)\n",
    "limites_regionais.rename(columns={'Cod_ibge': 'cod_ibge',\n",
    "                                  'Municipios': 'municipio'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIB = pd.read_csv(path_PIB, index_col=0)\n",
    "# O PIB não possui registros para o ano de 2022\n",
    "PIB = PIB[PIB['Ano'].isin([2014, 2016, 2018, 2020])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "EST_POP = pd.read_csv(path_est_pop, index_col=0)\n",
    "EST_POP = EST_POP[EST_POP['Ano'].isin([2014, 2016, 2018, 2020])]\n",
    "cols = ['razao_sexo', 'id_media', 'dens_demog']\n",
    "EST_POP[cols] = EST_POP[cols].replace({',': '.'}, regex=True).apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipdm = pd.read_csv(path_ipdm, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Junção das Bases de acordo com o ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def juncao_por_ano(ipdm, limites_regionais, EST_POP, PIB, ano):\n",
    "    \n",
    "    caminho_indices_criminais = f\"indices_criminais\\{ano}\\indices_criminais{ano}.csv\"\n",
    "    indices_criminais = pd.read_csv(caminho_indices_criminais)\n",
    "        \n",
    "    ipdm_ano = ipdm[ipdm['Ano'] == ano].copy()\n",
    "    EST_pop_ano = EST_POP[EST_POP['Ano'] == ano].copy()\n",
    "    PIB_ano = PIB[PIB['Ano'] == ano].copy()\n",
    "    \n",
    "    #Padronização dos municipios\n",
    "    ipdm_ano['Municipio'] = ipdm_ano['Municipio'].apply(lambda x: unidecode.unidecode(x))\n",
    "    EST_pop_ano['Municipio'] = EST_pop_ano['Municipio'].apply(lambda x: unidecode.unidecode(x))\n",
    "    PIB_ano['Municipio'] = PIB_ano['Municipio'].apply(lambda x: unidecode.unidecode(x))\n",
    "    limites_regionais['Municipio'] = limites_regionais['Municipio'].apply(lambda x: unidecode.unidecode(x))\n",
    "    indices_criminais['Municipio'] = indices_criminais['Municipio'].apply(lambda x: unidecode.unidecode(x))\n",
    "    \n",
    "    df_merge1 = pd.merge(ipdm_ano, EST_pop_ano, on=['Ano', 'cod_ibge', 'Municipio'], how='inner')\n",
    "    df_final = pd.merge(df_merge1, PIB_ano, on=['Ano', 'Municipio'], how='inner')\n",
    "    df_final = limites_regionais.merge(df_final, on=['cod_ibge', 'Municipio'], how='inner')\n",
    "    df_final = df_final.merge(indices_criminais, on=['cod_ibge', 'Municipio'], how='inner')\n",
    "    \n",
    "    df_final.drop(columns={'Ano_y'}, inplace=True)\n",
    "    df_final.rename(columns={'Ano_x': 'Ano'}, inplace=True)\n",
    "    \n",
    "    return df_final\n",
    "    \n",
    "    \n",
    "df_2014 = juncao_por_ano(ipdm, limites_regionais, EST_POP, PIB, 2014)\n",
    "df_2016 = juncao_por_ano(ipdm, limites_regionais, EST_POP, PIB, 2016)\n",
    "df_2018 = juncao_por_ano(ipdm, limites_regionais, EST_POP, PIB, 2018)\n",
    "df_2020 = juncao_por_ano(ipdm, limites_regionais, EST_POP, PIB, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportar_df(gdf, ano, caminho_destino='Base_final'):\n",
    "    diretorio = os.path.join(caminho_destino, str(ano))\n",
    "    os.makedirs(diretorio, exist_ok=True)\n",
    "    \n",
    "    arquivo = os.path.join(diretorio, f\"{ano}.shp\")\n",
    "    gdf.to_file(arquivo, driver='ESRI Shapefile')\n",
    "    print(f\"Exportado: {arquivo}\")\n",
    "    \n",
    "exportar_df(df_2014, 2014)\n",
    "exportar_df(df_2016, 2016)\n",
    "exportar_df(df_2018, 2018)\n",
    "exportar_df(df_2020, 2020)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
